%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction}
\section{Motivation}
Data centers increasingly use server virtualization to
reduce operating costs, simplify administrative tasks and improve 
performance scalability. Through virtualization, it is
possible to maximize isolation and resource utilization at the same time:
each application is typically assigned a dedicated server, 
while several virtual servers are consolidated on powerful host machines
to reduce wasted cycles. The use of techniques such as memory overcommitment (including 
\emph{transparent page sharing, ballooning} and \emph{hypervisor swapping}) \cite{waldspurger2002memory} 
has further improved the consolidation ratios and cost-effectiveness 
of server virtualization, and augurs well for the future of the technology.

Given the success of server virtualization, many companies are 
extending the use of virtualization to their desktop computers.
In a Virtual Desktop Infrastructure \cite{vmwarevdi} (VDI), 
desktop operating systems and applications are hosted in 
virtual machines that reside in a data center; 
users access virtual desktops from desktop PCs or thin clients
via a remote display protocol. A VDI provides simplicity 
in administration and management: applications
can be centrally added, deleted, upgraded and patched. 
Furthermore, desktop virtualization promises even
higher consolidation ratios than server virtualization
because desktop vitual machines (VMs) typically require
less resources than server VMs.

Consolidation ratios (or VM density per host) in data centers
are expected to increase in the future, not only because of
improvements in virtualization technology, but also because
new generations of processors support more cores and 
more memory \cite{hansen2010lithium}. 
While a high VM density per host is desireable in general for effective 
resource utilization, it can be problematic in certain scenarios:
correlated spikes in the CPU/memory usage of VMs can suddenly 
cripple host machines. For instance, a \emph{boot storm} \cite{hansen2010lithium, 
liao2011vmstore, meng2010tide, rajan2010vdc, vaghani2010virtual}
can occur after some software is installed or updated, requiring hundreds 
or thousands of identical VMs to reboot at the same time.
Bootstorms can be particularly frequent (and troubling) in VDIs because 
users typically show up to work at roughly the same time
in the morning each day.

To avoid VM bootstorms from causing the latency of booting machines
to be prohibitively high, data centers must either 
boot machines in a staggered fashion, or invest in expensive 
or extra-provisioned hardware. There is anecdotal evidence
that VDI users sometimes leave their desktop computers running
overnight to avoid morning boot storms, which
represents an unnecessary addition to already exorbitant
energy requirements of data centers. Data deduplication \cite{clements2009deduplication} 
has been proven to reduce the memory footprint of concurrently
booting machines. However, while data deduplication reduces
the stress on the memory subsystem, it can overwhelm the CPU, 
fibre channel, bus infrastructure or controller resources 
which must keep up with reduced memory latency.\cite{netappstorm}. 

With the spread of virtualization, it is important to address the
bootstorm problem in a way that does not involve simply skirting around it. 
For instance, staggered boots may not be 
possible if an urgent security update must be propagated to
all running VMs at once. Data deduplication is partly effective because 
identical VMs load the same data from disk when they boot up.  

There is a need 
for a systematic way to boot hundreds of potentially
identical VMs without throttling the hosts in a data-center.
If the identical VMs execute mostly the same set of instructions when they boot up,
perhaps there is a way to deduplicate \emph{execution} rather than just data?

Area of inquiry: given different identical VM images, can we 
make the boot process more deterministic? If so, 
deduplication of execution may be a possibility.
\section{Goal of Thesis}

Data deduplication is partly effective because many VMs load
the same data from disk when they boot up.  There is a need 
for a systematic way to boot hundreds of potentially
identical VMs without throttling the hosts in a data-center.
If the identical VMs execute mostly the same set of instructions when they boot up,
perhaps there is a way to deduplicate \emph{execution} rather than just data?

Not pursuing a full solution to the bootstorm problem.

Area of inquiry: given different identical VM images, can we 
make the boot process more deterministic? If so, 
deduplication of execution may be a possibility.

1) Statistically understand non-determinism 
in the case of linux services.

2) Figure out the context in which non-determinism
arises and find ways to control it.

Motivated by boostorm problem, because not only can we
do a deduplication of execution, we can improve
page-sharing and improve deduplication of data as well,
by making execution more deterministic.

...but studying non-determinism is an interesting question in its
own right, as explained in the next section.

\section{Importance of Deterministic Execution}\label{ch1:whydeterminism}

Deterministic execution of programs can be beneficial in many
different scenarios, and has motivated the design of Kendo,
a system which enables deterministic multithreading
in applications\cite{}. Our tool complements Kendo because 
it focuses on deterministic execution of single-threaded services in Linux,
at the granularity of individual instructions and their side-effects in
memory.

The motivations for deterministic multhreading listed in
\cite{} apply to this thesis as well.

\subsection{Mainstream Computing and Security}


\subsection{Repeatability}
Users expect programs to produce the same outputs, given the same
inputs. For safety-critical systems, it may
be even better if we can guarantee that given the same inputs,
a program would always execute some {\em precise} 
set of instructions, in the same order, with
the same side-effects. Record/replay systems are not suitable for 
achieving such strong guarantees of repeatability, given the storage
overhead for logs and the typically enormous input space. 
Our system, like Kendo, requires minimal storage to achieve
single-threaded determinism. 

\subsection{Debugging}
Determinism is important for debugging, because developers
often need to reproduce erroneous behavior in
order to diagnose and fix it. Nondeterminism is typically
a major issue for debugging multithreaded applications,
and is a lesser issue for single-threaded
applications. Our work will help developers
easily reproduce erroneous behavior given
the same input for single-threaded applications. 
Record/replay systems have high overhead, so it is unlikely
that the initial buggy execution of a program was recorded.
Deterministic execution also precludes the need for storing
many gigabytes of logs needed for record/replay.

\subsection{Testing}
Deterministic execution in general facilitates testing,
because outputs and internal state can be checked at 
certain points with respect to expected values. Our version
of determinism allows for a particularly strong kind
of test case that may be necessary for safety-critical 
systems: with deterministic execution, a program 
must execute the exact same instructions 
across different executions, for the same inputs.
Test cases can check for deviations from 
the expected instruction sequences.

\section{Contributions}
% Challenges of Determinstic Execution :: Helloworld.c


\subsection{Thesis Organization}





% This is an example of how you would use tgrind to include an example
% of source code; it is commented out in this template since the code
% example file does not exist.  To use it, you need to remove the '%' on the
% beginning of the line, and insert your own information in the call.
%
%\tagrind[htbp]{code/pmn.s.tex}{Post Multiply Normalization}{opt:pmn}

% This is an example of how you would use tgrind to include an example
% of source code; it is commented out in this template since the code
% example file does not exist.  To use it, you need to remove the '%' on the
% beginning of the line, and insert your own information in the call.
%
%\tgrind[htbp]{code/be.s.tex}{Block Exponent}{opt:be}

