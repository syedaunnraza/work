%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Execution Profile of Linux Services} \label{ch:boot}
This chapter provides some background on the
Linux startup process (Section \ref{linuxboot}).  
It then describes how we collected user-level instruction
streams from some Linux services via dynamic instrumentation to 
measure nondeterminism in the Linux boot process (Section \ref{datacollection}).
Finally, it summarizes our results on the statistical nature
of nondeterminism in Linux services (Section \ref{bootresults}).

\section{The Linux Boot Process}\label{linuxboot}
When a computer boots up:
\begin{enumerate}
\item The BIOS (Basic Input/Output System) 
gets control and performs startup tasks for the specific hardware platform.
\item Next, the BIOS reads and executes code from a designated boot device 
that contains part of a Linux boot loader. Typically,
this smaller part (or phase 1) 
loads the bulk of the boot loader code (phase 2).
\item The boot loader may present the user with options for 
which operating system to load (if there are multiple available options).
In any case, the boot loader loads and decompresses the operating system
into memory; it sets up system hardware and
memory paging; finally, it transfers control to the kernel's
\texttt{start\_kernel()} function.
\item The \texttt{start\_kernel()} function performs the 
majority of system setup (including interrupts, remaining memory
 management, device initialization)
before spawning the \texttt{idle} process, the scheduler
and the user-space \texttt{init} process.
\item The scheduler effectively takes control of system management,
and kernel stays idle from now on unless externally called.
\item The \texttt{init} process executes scripts that set up all
non-operating system services and structures in order to allow 
a user environment to be created, and then presents the user with a login screen.
\end{enumerate}

\begin{figure}
  \centering
  \subfloat[Part 1][CPU utilization immediately after \texttt{init} is started.] 
           {\includegraphics[width=\textwidth, trim=2cm 8cm 2cm 8cm]{cpu-boot.pdf} \label{fig:a}} \\
  \subfloat[Part 2][CPU utilization 5 minutes after \texttt{init} is started.] 
           {\includegraphics[width=\textwidth, trim=2cm 8cm 2cm 8cm]{cpu-ss.pdf} \label{fig:b}} 
  \caption[CPU utilization profile for a sample Ubuntu VM during boot and post-boot.]%
          {CPU utilization profile for a sample Ubuntu VM during boot and post-boot.}
  \label{data:bootcpu}
\end{figure}

\begin{figure}
  \centering
  \subfloat[Part 1][Disk utilization and throughput immediately after \texttt{init} is started.] 
           {\includegraphics[width=\textwidth, trim=2cm 8cm 2cm 8cm]{hd-boot.pdf} \label{fig:hda}} \\
  \subfloat[Part 2][Disk utilization and throughput 5 minutes after \texttt{init} is started.] 
           {\includegraphics[width=\textwidth, trim=2cm 8cm 2cm 8cm]{hd-ss.pdf} \label{fig:hdb}} 
  \caption[Disk utilization and throughput profile for a sample Ubuntu VM during boot and post-boot.]%
          {Disk utilization and throughput profile for a sample Ubuntu VM during boot and post-boot.}
  \label{data:boothd}
\end{figure}

\noindent Figures \ref{data:bootcpu} and \ref{data:boothd}
illustrate the CPU usage and disk activity 
of an Ubuntu 10.10 VM that takes about 22 seconds
to complete the sixth step of the boot process (i.e. spawn 
the \texttt{init} process to set up the user environment).
The Linux kernel version is 2.6.35-27-generic
and the VM is configured with a single core processor
with 2048 Mb RAM. Generated using
the Bootchart utility \cite{mahkovec2005bootchart},
the figures illustrate that
the booting process involves high memory
and CPU overhead (Figures \ref{fig:a} and \ref{fig:hda}); they also 
illustrate the well-known fact that memory and CPU
overhead typically diminishes greatly after the boot
process is completed and the machine reaches
its steady-state (Figures \ref{fig:b} and \ref{fig:hdb}). This disparity
in CPU/memory usage is the source of the boot storm problem;
a single host can handle many VMs in
steady-state usage but gets crippled
when the same VMs boot up concurrently.

In the last step of the booting
process (step 6), \texttt{init} typically
runs many scripts located in 
specific directories (such as \texttt{/etc/rc}
or \texttt{/etc/init.d/}). While different Linux distributions
typically have their own variants of \texttt{init} binaries
(e.g. \texttt{SysV}, \texttt{systemd} or \texttt{Upstart}),
the \texttt{init} process always directly or indirectly launches several 
services and daemons to initialize the user desktop
environment. Figure \ref{boot:services} provides a
summary of the specific actions performed by \texttt{init} 
(through the subprocesses or daemons it launches)
for the same Ubuntu VM used for 
Figures \ref{data:bootcpu} and \ref{data:boothd}.
The \texttt{init} process actually launched 361 children processes (directly
and indirectly) over the 25 second period summarized by Figure \ref{boot:services}.
Most of them were ephemeral processes; several processes were repeatedly launched
in different contexts (e.g. \texttt{getty} or \texttt{grep}). The processes singled out
in Figure \ref{boot:services} are the ones that either 
stayed alive through most of the boot process till the end, performed important
boot actions, or spawned many sub-processes themselves.

\begin{figure}[]
  \center
  \includegraphics[width=1.0\textwidth, trim=0.5cm 1cm 1cm 1cm]{boottimeline.pdf}
  \caption[A summary of the actions performed by \texttt{init} for a booting VM]%
  {A summary of the actions performed by \texttt{init} for a booting VM;
  this figure has the same time line (0-25 seconds) as Figures \ref{fig:a} and 
  \ref{fig:hda}.}
  \label{boot:services}
\end{figure}


\section{Data Collection Scheme} \label{datacollection}
\begin{figure}[h]
  \center
  \includegraphics[width=1.0\textwidth, trim=1cm 1cm 1cm 1cm]
                  {naivedatacollection.pdf}
  \caption[Steps involved in measuring execution nondeterminism]%
  {Steps involved in measuring execution nondeterminism.}
  \label{data:naive}
\end{figure}

Pin and DynamoRio are runtime frameworks that enable inspection
and arbitrary transformation of user-mode application code as it executes.
We used both Pin and DynamoRio to study the behavior
of Linux services independently; this allowed us to verify
the accuracy of our results. However, we relied on Pin more 
than DynamoRio because it gets injected into application code
earlier than DynamoRio and therefore provides greater
instruction coverage for our purpose.  Figure \ref{data:naive} shows the simple steps involved
in collecting data on nondeterminism using
dynamic instrumentation. The next section 
explains each of these steps in detail, 
using a simple ``Hello, world!'' program as an illustrative example.

\subsection{Measuring nondeterminism in a simple $C$ program} \label{ch:hw}
This section outlines the data collection scheme
described in Figure \ref{data:naive} in detail with the help
of an example:  the simple ``Hello, world!'' program
outlined in Figure \ref{source:hw}.
For this example, we disabled ASLR (Address Space Layout
Randomization) on the Ubuntu VM described in section \ref{linuxboot}
by using \texttt{sysctl kernel\_randomize\_va\_space=0}. \newline

\begin{figure}[h]
  \lstset{frame=shadowbox, rulesepcolor=\color{Gray},
    basicstyle=\small, numbers=left, numberstyle=\footnotesize}
  \lstinputlisting[language=C]{helloworld.c}
  \caption[A ``Hello, world!'' program in C.]%
          {A ``Hello, world!'' program in C. }
          \label{source:hw}
\end{figure}

\noindent {\bf Execution Tracing Layer} \newline
As shown in Figure \ref{data:naive}, the first step
in data collection involves running the target program
a few times across identical VMs. Ideally, these 
different executions are scheduled concurrently or as
close as possible in time to model the boot storm scenario accurately. 
As part of the execution tracing layer, we wrote a Pin tool that:
\begin{enumerate}
\item logs each x86 instruction executed by 
  the target process, along with the 
  new values of any affected registers, 
\item records values written to or 
  read from memory,
\item intercepts all signals received, and records the instruction counts 
  corresponding to the timing of any signals, and
\item monitors all system calls made by the target process,
  and logs any corresponding side-effects to memory or registers.
\end{enumerate}
For simplicity, our Pin tool traces the main process or thread 
for an application and does not follow any child processes or threads 
that it spawns. This prevents
us from including the user-mode instructions executed from child processes in our traces, 
but we get sufficiently high coverage to get a good understanding 
of the target program's behavior. We treat spawned child processes as part of the outside
world, and trace their interactions with the original process
(e.g. via signals or pipes).

Implementation of the execution tracing layer required
a close examination of the Linux system call interface;
we had to identify the side-effects of each system call. 
Figure \ref{hw:logsys} shows an excerpt from a trace 
generated by our Pin tool while running the ``Hello, World'' 
program. Our tool records 
every instruction executed in user-space by the process
for the target application once Pin gets control; 
this allows us to include program initialization
and library code in our analysis. \newline

\begin{figure}[h]
  \center
  \includegraphics[scale=0.60, trim=2cm 1.5cm 2cm 1.5cm]{log.pdf}
  \caption[Excerpts from the log files generated by the execution tracing layer]%
          {Excerpts from the log files generated by the execution tracing layer.
          The top half shows x86 instructions executed 
          in user-space by the ``Hello, world!'' process, including instruction addresses, 
          limited symbolic information, affected register values and memory 
          addresses. The lower half shows part of the system call log.}
  \label{hw:logsys}
\end{figure}

\noindent {\bf Analysis Script} \newline
The analysis script uses the Linux \emph{diff} utility
to perform pairwise comparisons of the log files generated 
by multiple executions of the target application. 
Using the \texttt{suppress-common}, \texttt{side-by-side}
and \texttt{minimal} flags, the analysis script
produces two output files: 
\begin{enumerate}
\item A {\em delta} file
that contains only instructions that were 
either conflicting between the two logs or missing in one log, and
\item A {\em union} file that contains all instructions
executed in the two logs, but distinguishes instructions  
included in the delta file from others.
\end{enumerate}

\begin{figure}[h]
  \center
  \includegraphics[scale=0.7, trim=3cm 1.5cm 3cm 3cm]{log2.pdf}
  \caption[Excerpts from the side-by-side diff files generated by the analysis script]%
          {Excerpts from the diff files generated by the analysis script.
            The top half shows instructions from the delta file;
            these all have different side-effects in the two logs
            (as indicated by the $\vert$).
            The bottom half shows instructions from the union file.
            Conflicting instructions are highlighted; others are found in both logs.}
  \label{hw:logsys2}
\end{figure}

\noindent Figure \ref{hw:logsys2} shows an excerpt from the 
union and delta files generated for the ``Hello, world!''
program. Given several traces, the delta and union
files can be constructed from the two
executions that are the most different 
or have the median difference. The 
much smaller size of the delta file
makes it suitable for diagnosing
sources of nondeterminism
in an application. \newline

\noindent {\bf Visualization Script} \newline
The visualization script reads the union file to 
compute statistics on the extent of any differences in the
original logs, and generates diagrams to 
capture the different execution traces of the program.
 
In particular, it derives three key metrics
after processing the union file:
\begin{enumerate}
\item {\em Length of Common Prefix {\bf (P):}} This is 
the number of instructions common
to both logs starting from the beginning
and up to the point of first divergence.
\item {\em Longest Common Substring {\bf (LS):}}
This is the longest sequence of consecutive instructions 
that are common to both logs.
\item {\em Longest Common Subsequence {\bf (LCS):}}
Intuitively, this is the ``overlap'' in the logs;
it is the length of the longest sequence of identical instructions
in both logs. Instructions in the LCS must be in the same order
in both logs, but they are not required to be adjacent.
\end{enumerate}

\noindent For instance, if the first instance of a program
executes the instruction sequence $I_1 = [A, B, C, D, E, F]$,
and the second instance of the same program executes 
the instruction sequence $I_2 = [A, B, X, D, E, F, Y]$,
then: the common prefix is $[A, B]$; the longest
common substring is $[D, E, F]$, and the longest
common subsequence is $[A, B, D, E, F]$. 

In general, the longest common subsequence (LCS) of two traces is
arguably the best indicator of the extent of determinism
in two executions of a program; we therefore
use LCS and ``Determinism'' interchangeably from now on. 
The other two metrics are important 
for evaluating the feasibility of silhouette execution
a solution to the boot storm problem. In general,
we want the common prefix (P) and the longest common substring (LS)
of the two logs to be as large as possible to
ensure that concurrently booting VMs do not need to branch
execution or communicate with each other too quickly (see Chapter
\ref{ch:sil}).

For the ``Hello, world!'' program, if ASLR
is enabled, the two logs have very little
overlap ($< 1\%$), and the common
prefix and longest common substring
are on the order of $10$ instructions.
With ASLR disabled, one may 
expect the two traces to look identical (because
of the simplicity of the program), but
there is still some nondeterminism in the 
instruction sequences (see Table \ref{hw:stats}
and Figure \ref{hw:trace}).

\begin{table}[h]
\begin{center}
\begin{tabular}{||l|c||}\hline
  Common Prefix & 21.49 percent \\\hline
  Longest Common Substring & 67.70 percent \\\hline
  Longest Common Subsequence & 99.98 percent \\\hline
  Conflict Ratio (i.e. $1 - LCS$) & 0.02 percent \\\hline
  Conflicting Instructions & 32 \\\hline
\end{tabular}
\end{center}
\caption{Nondeterminism profile of ``Hello, world!'' program (ASLR disabled)}
\label{hw:stats}
\end{table}

\newpage
Figure \ref{hw:trace} shows divergences in program execution
over time. This representation allows
us to visually inspect the union file 
and figure out the distribution and nature of conflicting
instructions. For the ``Hello, world!'' program,
we can see that while divergences were 
spread out near the beginning and end of the program,
they were bursty and short-lived (as indicated
by the thin black lines). This is a common trend, 
even for complex programs such as Linux services,
as discussed in Section \ref{bootresults}.


\begin{figure}[h]
  \center
  \includegraphics[scale=0.80, trim=0.3cm 0cm 0cm 0cm]{trace.pdf}
  \caption[Visualization of ``Hello, world!'' program execution]% 
          {Visualization of ``Hello, world!'' program execution.
          The thin black lines represent conflicts between
          the two instances of the program.}
  \label{hw:trace}
\end{figure} 

\subsection{Quantifying Nondeterminism} \label{alt:stats}
As mentioned in the previous section, we use the 
common prefix (P), the longest common subsequence (LCS),
the longest substring (LS) and the distribution of
conflicting instructions in separate instruction
streams to measure nondeterminism.

\noindent While the conflict ratio measured by our analysis script is usually quite small (e.g. $0.02\%$
for ``Hello, world!''), its importance and impact is disproportionately larger.
As shown in Figure \ref{cascade:ex},  the analysis script 
ignores the cascade effect and only considers instructions that {\em originate} or actively {\em propagate}
nondeterminism in calculating the conflict ratio. 

\begin{figure}[h]
  \center
  \includegraphics[width=\textwidth, trim=1cm 7cm 1cm 0.5cm]{liveness.pdf}
  \caption[The cascade and propagation effects in measuring nondeterminism.]%
          {The top image shows an example of the cascade effect: the red
          instruction represents a real conflict in \texttt{eax}. The light-blue instructions
          have the same side-effects across the two logs because they do not touch \texttt{eax}.
          Despite this, the value of \texttt{eax} is different in the blue instructions and converges 
          only after it is written by the green instruction. The cascade effect refers to the 
          nondeterministic register state
          that results in the light-blue instructions because of an earlier conflict, even
          though the instructions themselves are not reading or writing any nondeterministic
          values. If we included the cascade effect, the measured conflict ratio in this
          trace excerpt is $(N+3)/(N+4)$ instead of the $1/(N+4)$ we will report.  \newline
          
          The bottom image shows an example of the propagation effect: the red instruction again
          represents a conflict in \texttt{eax}. The light-blue instructions do not generate
          any nondeterminism themselves, but they have conflicting side-effects because they
          read \texttt{eax}. In this case, we report a conflict ratio of $1$.}
  \label{cascade:ex}
\end{figure} 
\noindent Ignoring the cascade effect while including the propagation effect effectively simulates a form of {\em taint analysis} \cite{newsome2005dynamic} on register and memory contents to measure the
true impact of any nondeterminism in a program. 
Our approach automatically groups instructions that generate and propagate
nondeterminism in the delta files, making it easier for us to 
diagnose the sources of nondeterminism.

One element missing from our study of nondeterminism is that
we do not account for timing-related
nondeterminism directly. For instance, two programs
that execute precisely the same set of instructions but 
take different amounts of time doing so (e.g. due
to variable latency of blocking system calls) are
fully deterministic according to our definition.
We deliberately exclude timing considerations because
it is acceptable for some VMs to lag behind others in the boot storm
scenario, as long as the same instructions are executed.
When timing-related nondeterminism affects program execution
e.g. through differences in signal delivery, I/O ordering
or time-related system calls (see Chapter \ref{ch:src}),
it automatically gets factored in our analysis.

\section{Results for Linux services} \label{bootresults}
Table \ref{linux:stats} shows the results from applying our data
collection scheme on a set of Linux services and daemons
that are typically launched at boot. \newline

\begin{table}[h]
\begin{center}
\begin{tabular}{||l|c|c|c||}\hline
  Application & Prefix (P) & Longest Substring (LS) &
  Determinism (LCS) \\
  \hline \hline
  \texttt{acpid}, 20 loop iterations & 20.99\% & 66.84\% & 99.98\%
  \\\hline
  \texttt{anacron}, 7 loop iterations & 0.65\% & 87.27\% & 99.21\%
  \\\hline
  \texttt{cups}, 10 loop iterations & 0.44\% & 12.87\% & 85.08\%
  \\\hline
  \texttt{cron}, 5 loop iterations & 1.54\% & 57.11\% & 99.94\% 
  \\\hline 
  \texttt{ntp}, 30 loop iterations & 2.46\% & 4.74\% & 81.66\%
  \\\hline
  \hline 
  {\bf Weighted Average} & {\bf 0.84}\% & {\bf 26.41}\% & {\bf 87.89}\%
  \\\hline 
\end{tabular}
\caption{Nondeterminism profile of Linux services and daemons (ASLR disabled). \newline
The average reported here is weighted-average computed based on the number of instructions
executed by each program. The period over which the 
programs were profiled was selected to be representative
of their execution typically till the login screen is shown.
Typically, the programs ran for 3-5 {\em true} (i.e without
instrumentation overhead) minutes.}
\label{linux:stats} 
\end{center}
\end{table}

\newpage 
We can immediately see that:
\begin{enumerate}
\item The common prefix (P) 
in our sample of Linux services is on average about $1\%$,
which is quite small and indicates that nondeterminism 
typically surfaces relatively early in program execution. 

\item The longest substring (LS), usually close to $26\%$,
is substantially larger than the common prefix (P).
This shows that execution typically does not permanently
diverge after the initial differences.

\item The longest common subsequence (LCS) or general determinism
is in general much higher -- about $88\%$ on average -- 
which indicates that a large majority of instructions 
in the Linux services overlap across
different executions. 
\end{enumerate}

\noindent Given the discussion in Section \ref{alt:stats}, a conflict ratio
of about $12\%$ on average hints that there is little but non-trivial nondeterminism 
in our sample programs, despite a very high average LCS.

\begin{figure}
  \center
  \includegraphics[trim=4cm 0cm 0cm 0cm, width=1.1\textwidth]{ntp-ch2.png}
  \caption[Visualization of \texttt{ntp} program execution (14 iterations)]% 
          {Visualization of \texttt{ntp} program execution (14 iterations).
          The thin black lines represent conflicts between
          the two instances of the program, whereas
          the thin blue or red lines represent control flow
          divergences.}
  \label{ntp:tracech2}
\end{figure} 

The distribution of the $12\%$ conflicting instructions
is surprisingly similar across different programs.
Figure \ref{ntp:tracech2}, an execution profile of \texttt{ntp}
(for the first 14 out of 30 iterations) is representative
of most execution traces. Generally,
conflicting instructions are spread throughout
the traces but tend to occur more frequently
towards the end. Nondeterminism does not seem to cause permanent 
execution divergences, even though there is significant
control-flow divergence in some programs. In fact, execution seems to
diverge and re-converge very frequently (i.e. nondeterminism is bursty).
The execution profile of \texttt{cron} is somewhat unique
because it has a higher LCS and LS than other traces. It is
difficult to reconcile the low measured conflict ratio for \texttt{cron} (less
than $2\%$), with the higher conflict ratio visually suggested by 
Figure \ref{ch2:crona}. Figure \ref{ch2:cronb} 
explains this discrepancy: it shows that while
the absolute number of conflicting instructions is small,
these conflicts occur in bursts and visually group together. 
While the bursty nature of nondeterminism
is particularly prominent in Figure \ref{ch2:cronb},
it is common to all the services we profiled. Table \ref{burst:stats}
shows that the longest control flow divergence 
or the longest string of consecutive conflicts
is typically very small (i.e. $<<1\%$) 
for most of our sample programs.

\begin{figure}
  \centering
  \subfloat[Part 1][The thin black lines represent conflicts between the two instances of the program.]
           {\includegraphics[width=1.0\textwidth, trim=4cm 0cm 0cm 2cm]{cron-ch2.png} \label{ch2:crona}} \\
  \subfloat[Part 2][Looking closely at the \texttt{cron} program execution reveals that conflicts occur in short bursts that visually group together.]
           {\includegraphics[width=0.7\textwidth, trim=2cm 0cm 0cm 0.5cm]{cronzoom-ch2.pdf} \label{ch2:cronb}} 
  \caption[Visualization of execution differences in \texttt{cron} (20 iterations).]%
          {Visualization of execution differences in \texttt{cron} (20 iterations).}
  \label{cron:ch2}
\end{figure}

\begin{table}
\begin{center}
\begin{tabular}{||l|c|c|c||}\hline
  Application & Max. Consecutive Conflicts & Max. Control Flow Divergence \\
  \hline \hline
  \texttt{acpid}, 20 loop iterations & 0.0000\% & 0.0019\% 
  \\\hline
  \texttt{anacron}, 7 loop iterations & 0.0335\% & 0.0021\% 
  \\\hline 
  \texttt{cups}, 10 loop iterations & 0.0120\% & 1.8500\% 
  \\\hline 
  \texttt{cron}, 5 loop iterations & 0.0004\% & 0.0002\% 
  \\\hline 
  \texttt{ntp}, 30 loop iterations & 0.0523\% & 0.3223\% 
  \\\hline 
  \hline 
  {\bf Weighted Average} & {\bf 0.0185}\% & {\bf 1.290}\% %
  \\\hline 
\end{tabular}
\end{center}
\caption{Measuring burstiness of nondeterminism in Linux services. \newline
The table shows the maximum number of consecutive instructions that conflict
in their side-effects or control-flow as a fraction of 
the total instructions of a program. These numbers are
only a small fraction of the 12\% conflicting
instructions in a program (see Table \ref{linux:stats}),
which establishes that execution differences are short-lived in our 
sample programs.} 
\label{burst:stats}
\end{table}


\newpage \section{Summary}
This chapter presented a brief overview of the Linux boot process,
and demonstrated our methodology for both quantifying and measuring nondeterminism
in programs using dynamic instrumentation. By analyzing user-mode
instructions executed by Linux boot services and daemons, we offered
evidence that Linux services execute highly overlapping instruction
sequences across different runs. We also showed
that any conflicts or nondeterminism in such services occurs in bursts;
nondeterminism does not cause executions to permanently diverge;
divergence and convergence occur very quickly and repeatedly in our
traces.

Chapters 3 will offer insight into the sources 
of nondeterminism behind these statistics. 
Chapter 4 will look at the implications of our results 
for the feasibility of silhouette solution as a solution to the boot storm problem.

