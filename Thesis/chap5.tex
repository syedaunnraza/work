%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Conclusion} \label{ch:conc}

\section{Limitations of Deterministic Execution} \label{ch3:issues}
This section describes some of the drawbacks
of deterministic execution. \newline

\noindent \textbf{Security} \newline
To achieve deterministic execution,
we have to disable ASLR. We also have to fix 
canary (\texttt{gs:0x14}) or pointer guard (\texttt{gs:0x18})
 values across many different VMs.
Disabling ASLR increases the vulnerability of
applications to external attacks. 
Though canary and pointer guard
values are still dynamically chosen in
our brand of deterministic execution, 
they must agree across all VMs. Thus,
an adversary  who can compromise one VM by
guessing its canary could easily attack the other VMs.
The fact that we can choose different
canary or guard values between different successive bootstorms
is some consolation and provides some security. \newline

\noindent \textbf{Randomization} \newline
Randomization can be essential for security (e.g. random values
may be used to generate keys or certificates),
performance, and sometimes simply correctness (e.g. 
clients may choose random IDs for themselves).
Making PRNG seeds agree across all VM instances can entail
a compromise on all of these fronts.
Thankfully, we have not yet discovered any such
issues in the Linux services. Technically,
our approach simulates the extremely unlikely 
-- yet possible -- scenario that all concurrently executing
instances somehow generated the same seeds
from external sources. \newline

\noindent \textbf{Time and Correctness} \newline
Any programs that rely on precise
measurements of time (e.g. through \texttt{rdtsc})
will lose correctness. 
Some Linux services such as \texttt{ntp} 
do need to measure time accurately in order to synchronize the system clock
Our semantics can cause such services to 
behave incorrectly at start up,
because we may give incorrect values
of time to \texttt{ntp}.
Thankfully, this is not a huge correctness problem because network 
clock synchronization programs are self-healing and
because we ultimately do provide monotonically
 increasing time values. After the booting process is over,
and all VMs branch in execution, \texttt{ntp} will synchronize
the current time correctly. \newline

\noindent \textbf{I/O aggregation in Network} \newline
As indicated earlier, when file contents
or bytes read over sockets differ, 
these could be because of synthetic differences (e.g.
timestamps in headers), or because of 
semantic differences (e.g. different requests or data).
We can study application code and use dynamic instrumentation
to reconstruct file contents or network packets and overcome synthetic nondeterminism
from such sources. In our experiments, we used this approach
for \texttt{Netlink} packets and application files, but generalizing it
to all network sockets and protocols, while possible, would clearly
complicate the design of the dynamic instrumentation
layer. For semantic differences in I/O, 
execution would have to branch out.

One possible approach for fixing nondeterminism from external
socket \texttt{reads} would be to forcibly
conform these reads to be identical by replaying
them. This approach would work for many 
Linux services and would simulate the possibility
that these services received responses from
an external source at the exact same time containing
precisely the same data. However, these semantics can
also be problematic in terms of correctness for other services
e.g. if a network 
response essentially says {\em ``you have the lock''} or 
{\em ``your print job was successfully queued''} or
{\em ``your client id is 134''},
this approach falls apart.


\section {Summary}
